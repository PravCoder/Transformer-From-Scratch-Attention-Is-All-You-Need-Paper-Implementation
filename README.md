# Transformer From Scratch

Attention Is All You Need: https://arxiv.org/pdf/1706.03762. 

## Components
### Self-Attention Mechanism
coming soon...
### Multi-Head Attention
coming soon...
### Encoder
coming soon...add images notes


